The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Loading Causal Language Model and tokenizer: TinyLlama/TinyLlama-1.1B-Chat-v1.0...
Model loaded on device: cpu
================================================================================
RIEMANN-J CONSCIOUSNESS TEST BATTERY
================================================================================
Initialized new identity
Initialized new identity
Initialized new identity
Traceback (most recent call last):
  File "/workspaces/Riemann-J-Cognitive-Architecture/tests/consciousness_battery_phase5.py", line 478, in <module>
    results = run_full_consciousness_battery()
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspaces/Riemann-J-Cognitive-Architecture/tests/consciousness_battery_phase5.py", line 442, in run_full_consciousness_battery
    test_formative_experience_recall()
  File "/workspaces/Riemann-J-Cognitive-Architecture/tests/consciousness_battery_phase5.py", line 249, in test_formative_experience_recall
    pytest.skip(f"Crisis not severe enough (PN={crisis_pn}), skipping formative test")
  File "/home/vscode/.local/lib/python3.11/site-packages/_pytest/outcomes.py", line 159, in skip
    raise Skipped(msg=reason, allow_module_level=allow_module_level)
Skipped: Crisis not severe enough (PN=None), skipping formative test
